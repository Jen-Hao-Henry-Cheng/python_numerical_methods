{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c8a22e-c8fc-4a13-b172-47ece9048421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sym\n",
    "import matplotlib.pyplot as plt\n",
    "from newton_raphson import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2978d6c-2ff6-4fba-b606-95e5dd809107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grad_by_difference(symFunc, valueXk, delta):\n",
    "    fk = symFunc.subs({x1: valueXk[0], x2: valueXk[1], x3: valueXk[2]})\n",
    "    fk_x1 = f.subs({x1: valueXk[0] + delta, x2: valueXk[1], x3: valueXk[2]})\n",
    "    fk_x2 = f.subs({x1: valueXk[0], x2: valueXk[1] + delta, x3: valueXk[2]})\n",
    "    fk_x3 = f.subs({x1: valueXk[0], x2: valueXk[1], x3: valueXk[2] + delta})\n",
    "    grad = np.array([(fk_x1 - fk)/delta, (fk_x2 - fk)/delta, (fk_x3 - fk)/delta])\n",
    "    return grad\n",
    "\n",
    "def find_optimal_alpha(symFunc, symVar):\n",
    "    f_1st_derv = sym.diff(symFunc, symVar)\n",
    "    f_2nd_derv = sym.diff(f_1st_derv, symVar)\n",
    "\n",
    "    f_1st_derv = sym.lambdify(alpha, f_1st_derv, 'numpy')\n",
    "    f_2nd_derv = sym.lambdify(alpha, f_2nd_derv, 'numpy')\n",
    "\n",
    "    optValue, Iter = newton_raphson(f_1st_derv, f_2nd_derv, 0)\n",
    "    return optValue, Iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e436c66-e8fc-4e96-ac96-0a1ea3410d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 3 x_{1}^{2} - 5 x_{1} + x_{2}^{2} + 2 x_{2} + 2 x_{3}^{2}$"
      ],
      "text/plain": [
       "3*x1**2 - 5*x1 + x2**2 + 2*x2 + 2*x3**2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2, x3, alpha = sym.symbols('x1 x2 x3 alpha')\n",
    "A = 3\n",
    "B = 2\n",
    "C = 2\n",
    "f = A*x1**2 + x2**2 + B*x3**2 - 5*x1 + 2*x2\n",
    "f # display f(x1, x2, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af480ee-c2c3-494d-8a69-591e61a547b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intial guess x0: [[2. 2. 3.]]\n"
     ]
    }
   ],
   "source": [
    "maxIter = 100;\n",
    "delta = 1.0e-05\n",
    "epsilon = 1.0e-04\n",
    "\n",
    "x = np.empty(shape=[0, 3])\n",
    "x = np.append(x, [[C, B, A]], axis=0) # initial value\n",
    "print(f'intial guess x0: {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4665c761-73ee-467e-b476-06d5914320a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 0, grad: [7.00002999991511 6.00000999995132 12.0000199999026], dir:[-7.00002999991511 -6.00000999995132 -12.0000199999026], x: [0.298298857709230, 0.541402841016822, 0.0828056820336438], alpha: 0.24309912133396663, error: 6.07749261924030\n",
      "k: 1, grad: [-3.21017685374070 3.08281568200952 0.331242728135450], dir:[1.73800667269612 -4.66677179696948 -0.340386191641637], x: [0.859843630418761, -0.966417208920743, -0.0271720813556951], alpha: 0.32309701771076854, error: 2.17934258603644\n",
      "k: 2, grad: [0.159091782503396 0.0671755821635145 -0.108668325404793], dir:[-0.154823147542232 -0.0693914523955353 0.0720342548693119], x: [0.826857159015083, -0.981201685250295, -0.0118245320644393], alpha: 0.213059041411619, error: 0.0631184970244860\n",
      "k: 3, grad: [-0.0388270459339424 0.0376066294549560 -0.0472781282567780], dir:[0.0296053861478528 -0.0593542587620206 0.0609130819693010], x: [0.833687461005693, -0.994895393204272, 0.00222881427434034], alpha: 0.2307114643429503, error: 0.0345773562833654\n",
      "k: 4, grad: [0.00215476605447407 0.0102192136086643 0.00893525706757714], dir:[-0.00206358548897048 -0.0146020778450890 -0.00675953143573026], x: [0.832992649369489, -0.999811929811918, -4.71278283433844e-5], alpha: 0.33670116402644534, error: 0.00788729034653441\n",
      "k: 5, grad: [-0.00201410381706069 0.000386140408537017 -0.000168511338216604], dir:[0.000211144530030652 -0.000406988687451729 0.000166107192739071], x: [0.833176062007621, -1.00016546427878, 9.71627124944273e-5], alpha: 0.8686591980665792, error: 0.000681237645834333\n",
      "k: 6, grad: [-0.000913627973275766 -0.000320928528196873 0.000408650846495107], dir:[0.000957074484327230 3.97976927424483e-5 0.000568215142541403], x: [0.833274080334836, -1.00016138841705, 0.000155356195532623], alpha: 0.10241452344603047, error: 0.000160287671989437\n",
      "k: 7, grad: [-0.000325518012544990 -0.000312776826660865 0.000641424779956878], dir:[0.000447012622774670 0.000350578444230027 0.000758483122731844], x: [0.833250301924469, -1.00018003710321, 0.000115009408821258], alpha: -0.05319404677858563, error: 0.0000827738832398289\n",
      "[0.833250301924469, -1.00018003710321, 0.000115009408821258]\n"
     ]
    }
   ],
   "source": [
    "# Conjugate Gradient\n",
    "for k in range(maxIter):\n",
    "    # get gradient by finite difference\n",
    "    grad = get_grad_by_difference(f, x[k], delta)\n",
    "    \n",
    "    if k == 0:\n",
    "        direction = -grad;\n",
    "    else:\n",
    "        direction = -grad + (grad*np.transpose(grad)) / (pre_grad*np.transpose(pre_grad)) *pre_direction\n",
    "\n",
    "    pre_grad = grad\n",
    "    pre_direction = direction\n",
    "    # find optimal alpha\n",
    "    x_alpha = x[k] + alpha*direction\n",
    "    f_alpha = f.subs({x1: x_alpha[0], x2: x_alpha[1], x3: x_alpha[2]})\n",
    "    opt_alpha, Iter = find_optimal_alpha(f_alpha, alpha)\n",
    "    \n",
    "    # compute new x\n",
    "    x_new = [x_alpha[0].subs(alpha, opt_alpha), x_alpha[1].subs(alpha, opt_alpha), x_alpha[2].subs(alpha, opt_alpha)]\n",
    "\n",
    "    # save new x into array x\n",
    "    x = np.append(x, [x_new], axis=0)\n",
    "    \n",
    "    # error check\n",
    "    error = np.linalg.norm(x_new - x[k], 1)\n",
    "    print(f'k: {k}, grad: {grad}, dir:{direction}, x: {x_new}, alpha: {opt_alpha}, error: {error}')\n",
    "    if error < epsilon:\n",
    "        print(x_new)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
